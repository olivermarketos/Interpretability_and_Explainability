{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451d0001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "import yaml\n",
    "from Pneumonia_predictor import PneumoniaDataset, PneumoniaPredictorCNN\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from helper_funcs import init_writer\n",
    "from Trainer import Trainer\n",
    "from pathlib import Path\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58bb1377",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Load the configuration file\n",
    "with open(\"output/model/6_smaller_img_bs32_lr0.0001_epoch15_img_size224x224_config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "seed = config[\"seed\"]\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "model_output_dir = Path(config[\"model_output_dir\"])\n",
    "model_output_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da1316d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (4185, 3) \n",
      "Validation data shape: (1047, 3) \n",
      "Test data shape: (624, 3)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "train_data_df = pd.read_csv(f'{config[\"data_dir\"]}/train_data.csv')\n",
    "val_data_df = pd.read_csv(f'{config[\"data_dir\"]}/val_data.csv')\n",
    "test_data_df = pd.read_csv(f'{config[\"data_dir\"]}/test_data.csv')\n",
    "print(f\"Train data shape: {train_data_df.shape} \\nValidation data shape: {val_data_df.shape} \\nTest data shape: {test_data_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288b2769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Randomized label counts (should be same as original):\n",
      "encoded_label\n",
      "1    3883\n",
      "0    1349\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data_df = pd.concat([train_data_df, val_data_df], ignore_index=True)\n",
    "# randomise encoded label order\n",
    "label_map_df = train_data_df[['encoded_label', 'label']].drop_duplicates()\n",
    "# Convert to a dictionary: {encoded_value: text_label}\n",
    "# e.g., {1: 'PNEUMONIA', 0: 'NORMAL'}\n",
    "encoding_to_text_map = pd.Series(label_map_df.label.values, index=label_map_df.encoded_label).to_dict()\n",
    "\n",
    "original_encoded_labels = train_data_df['encoded_label'].to_numpy(copy=True)\n",
    "\n",
    "# 3. Shuffle these labels.\n",
    "np.random.shuffle(original_encoded_labels) \n",
    "\n",
    "# 4. Assign the shuffled labels back to the 'encoded_label' column.\n",
    "train_data_df['encoded_label'] = original_encoded_labels\n",
    "\n",
    "# 5. Update the 'label' (text) column to match the new 'encoded_label'.\n",
    "train_data_df['label'] = train_data_df['encoded_label'].map(encoding_to_text_map)\n",
    "\n",
    "print(\"\\nRandomized label counts (should be same as original):\")\n",
    "print(train_data_df['encoded_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e141438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = config['image_size']\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize(image_size),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=5),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d0f9629",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PneumoniaDataset(train_data_df, transform=train_transforms)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers= config['num_workers'])\n",
    "\n",
    "val_dataset = PneumoniaDataset(val_data_df, transform=val_transforms)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers= config['num_workers'])\n",
    "\n",
    "test_dataset = PneumoniaDataset(test_data_df, transform=val_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers= config['num_workers'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d13e992",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "# load model parameters\n",
    "model_params = {'image_size':config['image_size'],\n",
    "                'in_channels':config['in_channels'], \n",
    "                'conv_defs':config['conv_layers'], \n",
    "                'fc_defs':config['fc_layers'],\n",
    "                'fc_dropout':config['fc_dropout'],\n",
    "                'fc_batch_norm':config['fc_batch_norm']\n",
    "                }\n",
    "\n",
    "model = PneumoniaPredictorCNN(**model_params)\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# load training parameters\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config['weight_decay'])\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
    "                                                    mode='min',\n",
    "                                                    factor=config['factor'],\n",
    "                                                    patience=config['patience'],\n",
    "                                                    cooldown=config['cooldown'],\n",
    "                                                    min_lr=1e-7,\n",
    "                                                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timestamp = datetime.now().strftime('%d_%m_%H%M%S')\n",
    "model_identifier = (\n",
    "        f\"6_random_labels\"\n",
    "        f\"_bs{config['batch_size']}\"\n",
    "        f\"_lr{config['learning_rate']}\"\n",
    "        f\"_epoch{config['epochs']}\"\n",
    "        f\"_img_size{config['image_size'][0]}x{config['image_size'][1]}\"\n",
    "    )\n",
    "\n",
    "run_identifier = f\"{timestamp}_{model_identifier}\"\n",
    "config[\"run_identifier\"] = run_identifier\n",
    "\n",
    "final_model_path = model_output_dir / f\"{model_identifier}_final.pth\"\n",
    "best_model_path = model_output_dir / f\"{model_identifier}_best.pth\"\n",
    "\n",
    "\n",
    "writer = init_writer(config)\n",
    "logging.info(f\"Starting training run: {model_identifier}\")\n",
    "trainer = Trainer(model, optimizer, loss_fn, scheduler, config, device, writer, logging)\n",
    "trainer.train(train_loader, val_loader, config[\"epochs\"])\n",
    "\n",
    "# Save final model \n",
    "torch.save(model.state_dict(), final_model_path)\n",
    "logging.info(f\"Final model saved to {final_model_path}\")\n",
    "\n",
    "# Rename best model saved by trainer\n",
    "internal_best_path = model_output_dir / \"best_model.pth\"\n",
    "if internal_best_path.exists() and not config['full_trainset']: # Only rename if validation was done\n",
    "    internal_best_path.rename(best_model_path)\n",
    "    logging.info(f\"Best validation model renamed to {best_model_path}\")\n",
    "elif internal_best_path.exists():\n",
    "    internal_best_path.unlink() # Clean up intermediate file if no validation\n",
    "\n",
    "# Save config used for run\n",
    "config_path = model_output_dir / f\"{model_identifier}_config.yaml\"\n",
    "with open(config_path, \"w\") as f:\n",
    "    yaml.dump(config, f)\n",
    "logging.info(f\"Configuration saved to {config_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
