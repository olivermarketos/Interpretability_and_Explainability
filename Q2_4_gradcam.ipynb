{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbed8d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import visualization as viz\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from Pneumonia_predictor import PneumoniaPredictorCNN, PneumoniaDataset, PneumoniaPredictorCNN_gradcam\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import models\n",
    "from pytorch_grad_cam import (\n",
    "    GradCAM, FEM, HiResCAM, ScoreCAM, GradCAMPlusPlus,\n",
    "    AblationCAM, XGradCAM, EigenCAM, EigenGradCAM,\n",
    "    LayerCAM, FullGrad, GradCAMElementWise, KPCA_CAM, ShapleyCAM,\n",
    "    FinerCAM\n",
    ")\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "from pytorch_grad_cam.utils.image import (\n",
    "    show_cam_on_image, deprocess_image, preprocess_image\n",
    ")\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget, ClassifierOutputReST\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3841012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PneumoniaPredictorCNN(\n",
       "  (conv): Sequential(\n",
       "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (14): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (16): ReLU()\n",
       "    (17): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (18): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (19): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (20): ReLU()\n",
       "    (21): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (23): ReLU()\n",
       "    (24): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    (25): Conv2d(128, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (27): ReLU()\n",
       "    (28): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (30): ReLU()\n",
       "    (31): Dropout2d(p=0.4, inplace=False)\n",
       "    (32): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=4608, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_name = '6_random_labels_bs32_lr0.0001_epoch15_img_size224x224'\n",
    "batch_size = 1\n",
    "\n",
    "output_dir = Path('output/model/')\n",
    "model_path = Path(output_dir/f'{model_name}_final.pth')\n",
    "model_config = Path(output_dir/f'{model_name}_config.yaml')\n",
    "\n",
    "with open(model_config, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "seed = config['seed']\n",
    "torch.manual_seed(seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model_params  = {'image_size':config['image_size'],\n",
    "                'in_channels':config['in_channels'], \n",
    "                'conv_defs':config['conv_layers'], \n",
    "                'fc_defs':config['fc_layers'],\n",
    "                'fc_dropout':config['fc_dropout'],\n",
    "                'fc_batch_norm':config['fc_batch_norm']\n",
    "                }\n",
    "\n",
    "\n",
    "model =PneumoniaPredictorCNN(**model_params)\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))\n",
    "model.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dc64a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod test data and show  some images\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "test_data_df = pd.read_csv(f'data/test_data.csv')\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "test_dataset = PneumoniaDataset(test_data_df, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataiter = iter(test_loader)\n",
    "\n",
    "\n",
    "\n",
    "map_labels = {0: 'Normal', 1: 'Pneumonia'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5f8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i want to get the file name of the image from \n",
    "test_dataset = PneumoniaDataset(test_data_df, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataiter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f43ac485",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    target_layers = [model.conv[31]]\n",
    "\n",
    "    image_tensor, label, file_path_tuple = batch # Renamed 'image' to 'image_tensor' for clarity\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    targets = [ClassifierOutputTarget(0)]\n",
    "\n",
    "    outputs = model(image_tensor)           # (B,1) raw logits\n",
    "    logits  = outputs.squeeze(1)      # -> (B,)\n",
    "\n",
    "    # apply sigmoid & threshold at 0.5:\n",
    "    probs   = torch.sigmoid(logits)   # (B,) in [0,1]\n",
    "    preds   = (probs > 0.5).long()    # (B,) in {0,1}\n",
    "\n",
    "    cam_algorithm = GradCAM\n",
    "    with cam_algorithm(target_layers=target_layers,\n",
    "                    model=model,) as cam:\n",
    "\n",
    "        grayscale_cam = cam(input_tensor=image_tensor, targets=targets)\n",
    "        grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "        # Prepare original image for overlay.\n",
    "        # image_tensor is (B, C, H, W), e.g., (1, 1, 224, 224)\n",
    "        # Convert to (H, W, C) numpy array, normalized to 0-1 float for show_cam_on_image\n",
    "        image_for_overlay = image_tensor[0].cpu().numpy()  # shape: (C, H, W)\n",
    "        image_for_overlay = np.transpose(image_for_overlay, (1, 2, 0))  # shape: (H, W, C)\n",
    "\n",
    "        # denormalize the image\n",
    "        image_for_overlay = image_for_overlay * 0.5 + 0.5  # unnormalize\n",
    "\n",
    "        if image_for_overlay.shape[2] == 1:\n",
    "            img_for_overlay = np.repeat(image_for_overlay, 3, axis=2) # (H, W, 3)\n",
    "\n",
    "        cam_image = show_cam_on_image(image_for_overlay, grayscale_cam, use_rgb=True)\n",
    "\n",
    "        cam_image = cv2.cvtColor(cam_image, cv2.COLOR_RGB2BGR) # Convert back to BGR for cv2.imwrite\n",
    "\n",
    "\n",
    "    gb_model = GuidedBackpropReLUModel(model=model, device=device)\n",
    "    gb = gb_model(image_tensor, target_category=0)\n",
    "\n",
    "    gb_numpy_hwc = gb.transpose( 0, 1, 2)  # shape: (H, W, C)\n",
    "\n",
    "    gb_output_visual = deprocess_image(gb_numpy_hwc)\n",
    "\n",
    "    # create cam_gb \n",
    "    cam_mask_rgb = cv2.merge([grayscale_cam, grayscale_cam, grayscale_cam])\n",
    "\n",
    "    # 2. Multiply with gb_numpy_hwc.\n",
    "    #    gb_numpy_hwc is (H, W, C_in). If C_in is 1, it broadcasts: (H,W,3) * (H,W,1) -> (H,W,3)\n",
    "    #    The values in gb_numpy_hwc are raw gradients.\n",
    "    product_cam_gb = cam_mask_rgb * gb_numpy_hwc # (H, W, 3)\n",
    "\n",
    "\n",
    "    cam_gb_visual = deprocess_image(product_cam_gb)\n",
    "\n",
    "    out_dir = 'output/gradcam_layer31_random_labels/'\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    file_basename = os.path.basename(file_path_tuple[0])\n",
    "    file_name = os.path.splitext(file_basename)[0]\n",
    "    file_name = f'{file_name}_pred_{preds[0].item()}_prob_{probs[0].item():.3f}'\n",
    "\n",
    "    cam_output_path = os.path.join(out_dir, f'{file_name}_cam.jpg')\n",
    "    gb_output_path = os.path.join(out_dir, f'{file_name}_gb.jpg')\n",
    "    cam_gb_output_path = os.path.join(out_dir, f'{file_name}_cam_gb.jpg')\n",
    "\n",
    "    cv2.imwrite(cam_output_path, cam_image)\n",
    "    # cv2.imwrite(gb_output_path, gb_output_visual)     # Should now be (H,W,1) or (H,W,3) uint8\n",
    "    # cv2.imwrite(cam_gb_output_path, cam_gb_visual) # Should now be (H,W,3) uint8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44612687",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     images = \u001b[43mnorm_images\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# make labels floats if you didn't already:\u001b[39;00m\n\u001b[32m      4\u001b[39m     labels = norm_labels\n",
      "\u001b[31mNameError\u001b[39m: name 'norm_images' is not defined"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    images = norm_images\n",
    "    # make labels floats if you didn't already:\n",
    "    labels = norm_labels\n",
    "\n",
    "    outputs = model(images)           # (B,1) raw logits\n",
    "    logits  = outputs.squeeze(1)      # -> (B,)\n",
    "\n",
    "    # apply sigmoid & threshold at 0.5:\n",
    "    probs   = torch.sigmoid(logits)   # (B,) in [0,1]\n",
    "    preds   = (probs > 0.5).long()    # (B,) in {0,1}\n",
    "    print(f'Normal: predictions: {preds} | probabilities: {[round(p, 3) for p in probs.tolist()]}')\n",
    "\n",
    "    images = pneu_images\n",
    "    labels = pneu_labels\n",
    "    outputs = model(images)           # (B,1) raw logits\n",
    "    logits  = outputs.squeeze(1)      # -> (B,)\n",
    "\n",
    "    probs  = torch.sigmoid(logits)   # (B,) in [0,1]\n",
    "    preds  = (probs > 0.5).long()    # (B,) in {0,1}\n",
    "    print(f'Pneumonia: predictions: {preds} | probabilities: {[round(p, 3) for p in probs.tolist()]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
